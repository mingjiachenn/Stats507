{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6bd64728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "    for n in range(len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and\n",
    "                sample_list[m][2] != sample_list[n][2]):\n",
    "            li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b23e0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 2), (1, 9, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a6291",
   "metadata": {},
   "source": [
    "# Question 0 - Code review warmup [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b2656",
   "metadata": {},
   "source": [
    "**a. describe the task that the code accomplishes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba7519",
   "metadata": {},
   "source": [
    "The code selects tuples that the first element is unique from the sample_list.\n",
    "\n",
    "When the first element is equal, compare the 3rd element and choose the one with larger element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0153d09",
   "metadata": {},
   "source": [
    "**b. write a short code review**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8893df5",
   "metadata": {},
   "source": [
    "1. It is important to keep an approperiate indent while coding, since the indent caan affect the logical relationship between different commands.\n",
    "\n",
    "2. The number of tuple index begins from zero, to which we should pay attention when coding.\n",
    "\n",
    "3. To make the snippet more efficient, we can store the index of tuples that has already occured instead of using the `set` fuction to delete duplicate.\n",
    "\n",
    "4. Appropriate comments should be added to make the snippet more readable. \n",
    "\n",
    "5. We can use letter such as `l` to denotes the code `len(sample_list)`, so that the snippet can be more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a5e3a",
   "metadata": {},
   "source": [
    "# Question 1 - List of Tuples [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "85ceaf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b38b7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lis_tup(n,k=5,low=1,high=5):\n",
    "    lis = [tuple(np.random.uniform(low, high) for i in range(k)) for j in range(n)]\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "088968ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=6\n",
    "k=5\n",
    "low=1\n",
    "high=5\n",
    "\n",
    "ast_lis=lis_tup(n,k,low,high)\n",
    "\n",
    "# assert the type of the result is list\n",
    "assert type(ast_lis)==list\n",
    "\n",
    "# assert the list is composed by tuples\n",
    "for i in range(len(ast_lis)):\n",
    "    assert type(ast_lis[i])==tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f75a49",
   "metadata": {},
   "source": [
    "# Question 2 - Refactor the Snippet [40 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72141167",
   "metadata": {},
   "source": [
    "**a. encapsulate the code snippet from the warmup into a function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dfe0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_a(sample_list, first_cmp, second_cmp):\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    op = []\n",
    "    \n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][first_cmp] == sample_list[n][first_cmp] and\n",
    "                sample_list[m][second_cmp] != sample_list[n][second_cmp]):\n",
    "                li.append(sample_list[n])\n",
    "                \n",
    "        op.append(sorted(li, key=lambda dd: dd[second_cmp], reverse=True)[0])\n",
    "        \n",
    "    res = list(set(op))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b7dce",
   "metadata": {},
   "source": [
    "**b. write an improved version of the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "12c81834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_b(sample_list, first_cmp, second_cmp):\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    op = []\n",
    "    appeared_idx = []\n",
    "    l = len(sample_list)\n",
    "    \n",
    "    for m in range(l):\n",
    "        \n",
    "        # filter the tuples that have already appeared\n",
    "        if m in appeared_idx:\n",
    "            continue\n",
    "            \n",
    "        li = [sample_list[m]]\n",
    "        \n",
    "        for n in range(l):\n",
    "            if (sample_list[m][first_cmp] == sample_list[n][first_cmp] and\n",
    "                sample_list[m][second_cmp] != sample_list[n][second_cmp]):\n",
    "\n",
    "                appeared_idx.append(n)\n",
    "                li.append(sample_list[n])\n",
    "                \n",
    "        op.append(sorted(li, key=lambda dd: dd[second_cmp], reverse=True)[0])\n",
    "        \n",
    "    res = op\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19171b4a",
   "metadata": {},
   "source": [
    "**c. Write a function from scratch to accomplish the same task as the previous two parts. Your solution should traverse the input list of tuples no more than twice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "53e4732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_c(sample_list, first_cmp, second_cmp):\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    dic_tup = {}\n",
    "    \n",
    "    for tup in sample_list:\n",
    "        dic_add = {}\n",
    "        tup_add = True\n",
    "        \n",
    "        for key, value in dic_tup.items():\n",
    "            if key[first_cmp] == tup[first_cmp] and key[second_cmp] != tup[second_cmp]:\n",
    "                dic_tup[key].append(tup)\n",
    "                tup_add = False\n",
    "        \n",
    "        if tup_add:\n",
    "            dic_add[tup] = [tup]\n",
    "        \n",
    "        dic_tup = {**dic_add, **dic_tup}        \n",
    "                \n",
    "    res = set()\n",
    "    for value in dic_tup.values():\n",
    "        tup = sorted(value, key=lambda dd: dd[second_cmp], reverse=True)[0] \n",
    "        res.add(tup)\n",
    "        \n",
    "    res = list(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf68d2",
   "metadata": {},
   "source": [
    "**d. Use the function you wrote in question 1 to generate a list of tuples as input(s), run and summarize a small Monte Carlo study comparing the execution times of the three functions above (a-c).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7589ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c500c275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0.058450937271118164, 'b': 0.05696511268615723, 'c': 0.029476165771484375}\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "k = 100\n",
    "low = 0\n",
    "high = 10000\n",
    "\n",
    "sample_list = lis_tup(n, k, low, high)\n",
    "\n",
    "first_cmp=20\n",
    "second_cmp=80\n",
    "\n",
    "dic_time={}\n",
    "\n",
    "start_a=time.time()\n",
    "filter_tuple_a(sample_list, first_cmp, second_cmp)\n",
    "end_a=time.time()\n",
    "dic_time['a'] = end_a - start_a\n",
    "\n",
    "start_b=time.time()\n",
    "filter_tuple_b(sample_list, first_cmp, second_cmp)\n",
    "end_b=time.time()\n",
    "dic_time['b'] = end_b - start_b\n",
    "\n",
    "start_c=time.time()\n",
    "filter_tuple_c(sample_list, first_cmp, second_cmp)\n",
    "end_c=time.time()\n",
    "dic_time['c'] = end_c - start_c\n",
    "\n",
    "print (dic_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2a3232c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 9438 {'a': 5.840948820114136, 'b': 5.985069751739502, 'c': 2.7341392040252686}\n",
      "n = 1316 {'a': 0.10268020629882812, 'b': 0.10136914253234863, 'c': 0.05102992057800293}\n",
      "n = 3601 {'a': 0.7503077983856201, 'b': 0.7383172512054443, 'c': 0.3726468086242676}\n",
      "n = 8938 {'a': 5.259960889816284, 'b': 5.434670925140381, 'c': 2.436269760131836}\n",
      "n = 4602 {'a': 1.2742691040039062, 'b': 1.267091989517212, 'c': 0.6174421310424805}\n",
      "n = 4758 {'a': 1.3541769981384277, 'b': 1.3458051681518555, 'c': 0.6589140892028809}\n",
      "n = 7567 {'a': 3.468458890914917, 'b': 3.4456307888031006, 'c': 1.6771690845489502}\n",
      "n = 9381 {'a': 6.09217381477356, 'b': 5.7980310916900635, 'c': 2.6384458541870117}\n",
      "n = 5811 {'a': 2.004854917526245, 'b': 1.9901459217071533, 'c': 0.9884228706359863}\n",
      "n = 7109 {'a': 3.0337941646575928, 'b': 2.9936580657958984, 'c': 1.50691819190979}\n"
     ]
    }
   ],
   "source": [
    "#change the value of n\n",
    "\n",
    "k = 100\n",
    "low = 0\n",
    "high = 10000\n",
    "\n",
    "for i in range(10):\n",
    "    n = int(random.uniform(1000,10000))\n",
    "    sample_list = lis_tup(n, k, low, high)\n",
    "    first_cmp=20\n",
    "    second_cmp=80\n",
    "    \n",
    "    dic_time={}\n",
    "    start_a=time.time()\n",
    "    filter_tuple_a(sample_list, first_cmp, second_cmp)\n",
    "    end_a=time.time()\n",
    "    dic_time['a'] = end_a - start_a\n",
    "\n",
    "    start_b=time.time()\n",
    "    filter_tuple_b(sample_list, first_cmp, second_cmp)\n",
    "    end_b=time.time()\n",
    "    dic_time['b'] = end_b - start_b\n",
    "\n",
    "    start_c=time.time()\n",
    "    filter_tuple_c(sample_list, first_cmp, second_cmp)\n",
    "    end_c=time.time()\n",
    "    dic_time['c'] = end_c - start_c\n",
    "\n",
    "    print ('n =', n ,dic_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "52533dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 905 {'a': 0.06366086006164551, 'b': 0.05799388885498047, 'c': 0.03896212577819824}\n",
      "k = 713 {'a': 0.06366991996765137, 'b': 0.05911087989807129, 'c': 0.03723001480102539}\n",
      "k = 877 {'a': 0.0647287368774414, 'b': 0.05855393409729004, 'c': 0.03968310356140137}\n",
      "k = 164 {'a': 0.05972909927368164, 'b': 0.057990074157714844, 'c': 0.030751943588256836}\n",
      "k = 584 {'a': 0.06340193748474121, 'b': 0.059126853942871094, 'c': 0.03595995903015137}\n",
      "k = 416 {'a': 0.06201910972595215, 'b': 0.05912303924560547, 'c': 0.034750938415527344}\n",
      "k = 538 {'a': 0.06206393241882324, 'b': 0.05784177780151367, 'c': 0.03531002998352051}\n",
      "k = 296 {'a': 0.06004929542541504, 'b': 0.05782294273376465, 'c': 0.03232693672180176}\n",
      "k = 740 {'a': 0.0632939338684082, 'b': 0.05847883224487305, 'c': 0.03759312629699707}\n",
      "k = 692 {'a': 0.0638120174407959, 'b': 0.0596158504486084, 'c': 0.03708004951477051}\n"
     ]
    }
   ],
   "source": [
    "#change the value of k\n",
    "\n",
    "n=1000\n",
    "low = 0\n",
    "high = 10000\n",
    "\n",
    "for i in range(10):\n",
    "    k = int(random.uniform(100,1000))\n",
    "    sample_list = lis_tup(n, k, low, high)\n",
    "    first_cmp=20\n",
    "    second_cmp=80\n",
    "    \n",
    "    dic_time={}\n",
    "    start_a=time.time()\n",
    "    filter_tuple_a(sample_list, first_cmp, second_cmp)\n",
    "    end_a=time.time()\n",
    "    dic_time['a'] = end_a - start_a\n",
    "\n",
    "    start_b=time.time()\n",
    "    filter_tuple_b(sample_list, first_cmp, second_cmp)\n",
    "    end_b=time.time()\n",
    "    dic_time['b'] = end_b - start_b\n",
    "\n",
    "    start_c=time.time()\n",
    "    filter_tuple_c(sample_list, first_cmp, second_cmp)\n",
    "    end_c=time.time()\n",
    "    dic_time['c'] = end_c - start_c\n",
    "\n",
    "    print ('k =', k, dic_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "10f6f8de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low = 528 {'a': 0.06016898155212402, 'b': 0.058801889419555664, 'c': 0.030050992965698242}\n",
      "low = 232 {'a': 0.05928397178649902, 'b': 0.05861401557922363, 'c': 0.029837846755981445}\n",
      "low = 805 {'a': 0.05878496170043945, 'b': 0.058342933654785156, 'c': 0.029676198959350586}\n",
      "low = 570 {'a': 0.058966875076293945, 'b': 0.057994842529296875, 'c': 0.029675960540771484}\n",
      "low = 612 {'a': 0.05972409248352051, 'b': 0.058348894119262695, 'c': 0.030428171157836914}\n",
      "low = 989 {'a': 0.06330299377441406, 'b': 0.06014394760131836, 'c': 0.03131413459777832}\n",
      "low = 835 {'a': 0.05904984474182129, 'b': 0.058243751525878906, 'c': 0.030218124389648438}\n",
      "low = 385 {'a': 0.06399679183959961, 'b': 0.06223011016845703, 'c': 0.03027200698852539}\n",
      "low = 237 {'a': 0.05863213539123535, 'b': 0.058023929595947266, 'c': 0.02996993064880371}\n",
      "low = 481 {'a': 0.05891084671020508, 'b': 0.057859182357788086, 'c': 0.029750823974609375}\n"
     ]
    }
   ],
   "source": [
    "#change the value of low\n",
    "\n",
    "n=1000\n",
    "k=100\n",
    "high = 10000\n",
    "\n",
    "for i in range(10):\n",
    "    low = int(random.uniform(0,1000))\n",
    "    sample_list = lis_tup(n, k, low, high)\n",
    "    first_cmp=20\n",
    "    second_cmp=80\n",
    "    \n",
    "    dic_time={}\n",
    "    start_a=time.time()\n",
    "    filter_tuple_a(sample_list, first_cmp, second_cmp)\n",
    "    end_a=time.time()\n",
    "    dic_time['a'] = end_a - start_a\n",
    "\n",
    "    start_b=time.time()\n",
    "    filter_tuple_b(sample_list, first_cmp, second_cmp)\n",
    "    end_b=time.time()\n",
    "    dic_time['b'] = end_b - start_b\n",
    "\n",
    "    start_c=time.time()\n",
    "    filter_tuple_c(sample_list, first_cmp, second_cmp)\n",
    "    end_c=time.time()\n",
    "    dic_time['c'] = end_c - start_c\n",
    "\n",
    "    print ('low =', low, dic_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a1f20baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high = 59663 {'a': 0.058416128158569336, 'b': 0.05777120590209961, 'c': 0.029796838760375977}\n",
      "high = 81721 {'a': 0.05903911590576172, 'b': 0.0577239990234375, 'c': 0.029843807220458984}\n",
      "high = 59103 {'a': 0.05876016616821289, 'b': 0.06067681312561035, 'c': 0.03239297866821289}\n",
      "high = 75033 {'a': 0.059355974197387695, 'b': 0.05841183662414551, 'c': 0.030189037322998047}\n",
      "high = 80235 {'a': 0.05856204032897949, 'b': 0.058254241943359375, 'c': 0.030464887619018555}\n",
      "high = 25798 {'a': 0.0603177547454834, 'b': 0.05875802040100098, 'c': 0.030740976333618164}\n",
      "high = 93346 {'a': 0.05946803092956543, 'b': 0.058776140213012695, 'c': 0.030546188354492188}\n",
      "high = 34982 {'a': 0.060189247131347656, 'b': 0.05955100059509277, 'c': 0.031033992767333984}\n",
      "high = 14479 {'a': 0.05974006652832031, 'b': 0.058969974517822266, 'c': 0.030548095703125}\n",
      "high = 51997 {'a': 0.060140132904052734, 'b': 0.059590816497802734, 'c': 0.030652999877929688}\n"
     ]
    }
   ],
   "source": [
    "#change the value of high\n",
    "\n",
    "n=1000\n",
    "k=100\n",
    "low = 0\n",
    "\n",
    "for i in range(10):\n",
    "    high = int(random.uniform(10000,100000))\n",
    "    sample_list = lis_tup(n, k, low, high)\n",
    "    first_cmp=20\n",
    "    second_cmp=80\n",
    "    \n",
    "    dic_time={}\n",
    "    start_a=time.time()\n",
    "    filter_tuple_a(sample_list, first_cmp, second_cmp)\n",
    "    end_a=time.time()\n",
    "    dic_time['a'] = end_a - start_a\n",
    "\n",
    "    start_b=time.time()\n",
    "    filter_tuple_b(sample_list, first_cmp, second_cmp)\n",
    "    end_b=time.time()\n",
    "    dic_time['b'] = end_b - start_b\n",
    "\n",
    "    start_c=time.time()\n",
    "    filter_tuple_c(sample_list, first_cmp, second_cmp)\n",
    "    end_c=time.time()\n",
    "    dic_time['c'] = end_c - start_c\n",
    "\n",
    "    print ('high =', high, dic_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738252b",
   "metadata": {},
   "source": [
    "# Question 3 - [30 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "478bb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104999fa",
   "metadata": {},
   "source": [
    "**a. read and append the demographic datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c3262e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT'\n",
    "url2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT'\n",
    "url3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT'\n",
    "url4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT'\n",
    "\n",
    "df11_12 = pd.read_sas(url1)\n",
    "df11_12 = df11_12[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', 'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df11_12['year'] = ['2011-2012' for i in range(len(df11_12))]\n",
    "\n",
    "df13_14 = pd.read_sas(url2)\n",
    "df13_14 = df13_14[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', 'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df13_14['year'] = ['2013-2014' for i in range(len(df13_14))]\n",
    "\n",
    "df15_16 = pd.read_sas(url3)\n",
    "df15_16 = df15_16[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', 'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df15_16['year'] = ['2015-2016' for i in range(len(df15_16))]\n",
    "\n",
    "df17_18 = pd.read_sas(url4)\n",
    "df17_18 = df17_18[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', 'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df17_18['year'] = ['2017-2018' for i in range(len(df17_18))]\n",
    "\n",
    "df = pd.concat([df11_12, df13_14, df15_16, df17_18], axis=0)\n",
    "\n",
    "df['SEQN'] = df['SEQN'].astype('int')\n",
    "df['RIDAGEYR'] = df['RIDAGEYR'].astype('int')\n",
    "df['RIDRETH3'] = df['RIDRETH3'].astype('int')\n",
    "df['RIDSTATR'] = df['RIDSTATR'].astype('int')\n",
    "\n",
    "df = df.rename(columns={'SEQN': 'Respondent sequence number',\n",
    "                   'RIDAGEYR': 'Age in years of the participant at the time of screening.', \n",
    "                   'RIDRETH3': 'Recode of reported race and Hispanic origin information, with Non-Hispanic Asian Category',\n",
    "                   'DMDEDUC2': 'What is the highest grade or level of school {you have/SP has} completed or the highest degree {you have/s/he has} received?',\n",
    "                   'DMDMARTL': 'Marital status',\n",
    "                   'RIDSTATR': 'Interview and examination status of the participant.',\n",
    "                   'SDMVPSU': 'Masked variance unit pseudo-PSU variable for variance estimation',\n",
    "                   'SDMVSTRA': 'Masked variance unit pseudo-stratum variable for variance estimation',\n",
    "                   'WTMEC2YR': 'Both interviewed and MEC examined participants.',\n",
    "                   'WTINT2YR': 'Interviewed participants.'})\n",
    "\n",
    "\n",
    "f = open('NHANS.pkl', 'wb')\n",
    "\n",
    "pickle.dump(df, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a2895569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Respondent sequence number  \\\n",
      "0                          62161   \n",
      "1                          62162   \n",
      "2                          62163   \n",
      "3                          62164   \n",
      "4                          62165   \n",
      "...                          ...   \n",
      "9249                      102952   \n",
      "9250                      102953   \n",
      "9251                      102954   \n",
      "9252                      102955   \n",
      "9253                      102956   \n",
      "\n",
      "      Age in years of the participant at the time of screening.  \\\n",
      "0                                                    22           \n",
      "1                                                     3           \n",
      "2                                                    14           \n",
      "3                                                    44           \n",
      "4                                                    14           \n",
      "...                                                 ...           \n",
      "9249                                                 70           \n",
      "9250                                                 42           \n",
      "9251                                                 41           \n",
      "9252                                                 14           \n",
      "9253                                                 38           \n",
      "\n",
      "      Recode of reported race and Hispanic origin information, with Non-Hispanic Asian Category  \\\n",
      "0                                                     3                                           \n",
      "1                                                     1                                           \n",
      "2                                                     6                                           \n",
      "3                                                     3                                           \n",
      "4                                                     4                                           \n",
      "...                                                 ...                                           \n",
      "9249                                                  6                                           \n",
      "9250                                                  1                                           \n",
      "9251                                                  4                                           \n",
      "9252                                                  4                                           \n",
      "9253                                                  3                                           \n",
      "\n",
      "      What is the highest grade or level of school {you have/SP has} completed or the highest degree {you have/s/he has} received?  \\\n",
      "0                                                   3.0                                                                              \n",
      "1                                                   NaN                                                                              \n",
      "2                                                   NaN                                                                              \n",
      "3                                                   4.0                                                                              \n",
      "4                                                   NaN                                                                              \n",
      "...                                                 ...                                                                              \n",
      "9249                                                3.0                                                                              \n",
      "9250                                                3.0                                                                              \n",
      "9251                                                5.0                                                                              \n",
      "9252                                                NaN                                                                              \n",
      "9253                                                4.0                                                                              \n",
      "\n",
      "      Marital status  Interview and examination status of the participant.  \\\n",
      "0                5.0                                                  2      \n",
      "1                NaN                                                  2      \n",
      "2                NaN                                                  2      \n",
      "3                1.0                                                  2      \n",
      "4                NaN                                                  2      \n",
      "...              ...                                                ...      \n",
      "9249             1.0                                                  2      \n",
      "9250             4.0                                                  2      \n",
      "9251             5.0                                                  2      \n",
      "9252             NaN                                                  2      \n",
      "9253             3.0                                                  2      \n",
      "\n",
      "      Masked variance unit pseudo-PSU variable for variance estimation  \\\n",
      "0                                                   1.0                  \n",
      "1                                                   3.0                  \n",
      "2                                                   3.0                  \n",
      "3                                                   1.0                  \n",
      "4                                                   2.0                  \n",
      "...                                                 ...                  \n",
      "9249                                                2.0                  \n",
      "9250                                                2.0                  \n",
      "9251                                                1.0                  \n",
      "9252                                                1.0                  \n",
      "9253                                                1.0                  \n",
      "\n",
      "      Masked variance unit pseudo-stratum variable for variance estimation  \\\n",
      "0                                                  91.0                      \n",
      "1                                                  92.0                      \n",
      "2                                                  90.0                      \n",
      "3                                                  94.0                      \n",
      "4                                                  90.0                      \n",
      "...                                                 ...                      \n",
      "9249                                              138.0                      \n",
      "9250                                              137.0                      \n",
      "9251                                              144.0                      \n",
      "9252                                              136.0                      \n",
      "9253                                              142.0                      \n",
      "\n",
      "      Both interviewed and MEC examined participants.  \\\n",
      "0                                       104236.582554   \n",
      "1                                        16116.354010   \n",
      "2                                         7869.485117   \n",
      "3                                       127965.226204   \n",
      "4                                        13384.042162   \n",
      "...                                               ...   \n",
      "9249                                     18338.711104   \n",
      "9250                                     63661.951573   \n",
      "9251                                     17694.783346   \n",
      "9252                                     14871.839636   \n",
      "9253                                     39426.299948   \n",
      "\n",
      "      Interviewed participants.       year  \n",
      "0                 102641.406474  2011-2012  \n",
      "1                  15457.736897  2011-2012  \n",
      "2                   7397.684828  2011-2012  \n",
      "3                 127351.373299  2011-2012  \n",
      "4                  12209.744980  2011-2012  \n",
      "...                         ...        ...  \n",
      "9249               16896.276203  2017-2018  \n",
      "9250               61630.380013  2017-2018  \n",
      "9251               17160.895269  2017-2018  \n",
      "9252               14238.445922  2017-2018  \n",
      "9253               38645.740291  2017-2018  \n",
      "\n",
      "[39156 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d60eea",
   "metadata": {},
   "source": [
    "**b. read and append the oral health and dentition dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c90a447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "url5 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT'\n",
    "url6 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT'\n",
    "url7 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT'\n",
    "url8 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT'\n",
    "\n",
    "required_columns = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "df17_18_od = pd.read_sas(url8)\n",
    "for col in df17_18_od.columns:\n",
    "    if col.startswith('OHX'):\n",
    "        if (col.lstrip('OHX').rstrip('TC')).isdigit():\n",
    "            required_columns.append(col)\n",
    "        elif (col.lstrip('OHX').rstrip('CTC')).isdigit():\n",
    "            required_columns.append(col)\n",
    "df17_18_od = df17_18_od[required_columns]\n",
    "df17_18_od['year'] = ['2017-2018' for i in range(len(df17_18_od))]\n",
    "\n",
    "df11_12_od = pd.read_sas(url5)\n",
    "df11_12_od = df11_12_od[required_columns]\n",
    "df11_12_od['year'] = ['2011-2012' for i in range(len(df11_12_od))]\n",
    "\n",
    "\n",
    "df13_14_od = pd.read_sas(url6)\n",
    "df13_14_od = df13_14_od[required_columns]\n",
    "df13_14_od['year'] = ['2013-2014' for i in range(len(df13_14_od))]\n",
    "\n",
    "\n",
    "df15_16_od = pd.read_sas(url7)\n",
    "df15_16_od = df15_16_od[required_columns]\n",
    "df15_16_od['year'] = ['2015-2016' for i in range(len(df15_16_od))]\n",
    "\n",
    "df_od = pd.concat([df11_12_od, df13_14_od, df15_16_od, df17_18_od], axis=0, sort=False)\n",
    "\n",
    "df_od['SEQN'] = df_od['SEQN'].astype('int')\n",
    "df_od['OHDDESTS'] = df_od['OHDDESTS'].astype('int')\n",
    "\n",
    "df_od = df_od.rename(columns={'SEQN': 'Respondent sequence number',\n",
    "                        'OHDDESTS': 'Dentition Status Code'})\n",
    "\n",
    "f = open('OHXDEN.pkl', 'wb')\n",
    "\n",
    "pickle.dump(df_od, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a578c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Respondent sequence number  Dentition Status Code  OHX01TC  OHX02TC  \\\n",
      "0                          62161                      1      4.0      2.0   \n",
      "1                          62162                      1      4.0      4.0   \n",
      "2                          62163                      1      4.0      2.0   \n",
      "3                          62164                      1      4.0      2.0   \n",
      "4                          62165                      1      4.0      2.0   \n",
      "...                          ...                    ...      ...      ...   \n",
      "8361                      102952                      1      2.0      2.0   \n",
      "8362                      102953                      1      2.0      2.0   \n",
      "8363                      102954                      1      2.0      2.0   \n",
      "8364                      102955                      1      4.0      2.0   \n",
      "8365                      102956                      1      4.0      4.0   \n",
      "\n",
      "      OHX03TC  OHX04TC  OHX05TC  OHX06TC  OHX07TC  OHX08TC  ...  OHX23CTC  \\\n",
      "0         2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "1         4.0      1.0      1.0      1.0      1.0      1.0  ...      b'D'   \n",
      "2         2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "3         2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "4         2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "...       ...      ...      ...      ...      ...      ...  ...       ...   \n",
      "8361      2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "8362      2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "8363      2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "8364      2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "8365      2.0      2.0      2.0      2.0      2.0      2.0  ...      b'S'   \n",
      "\n",
      "      OHX24CTC  OHX25CTC  OHX26CTC  OHX27CTC  OHX28CTC  OHX29CTC  OHX30CTC  \\\n",
      "0         b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'Z'   \n",
      "1         b'D'      b'D'      b'D'      b'D'      b'D'      b'D'      b'U'   \n",
      "2         b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'Y'   \n",
      "3         b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'Z'   \n",
      "4         b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "8361      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
      "8362      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
      "8363      b'S'      b'S'      b'S'      b'S'      b'S'      b'F'      b'S'   \n",
      "8364      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
      "8365      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'   \n",
      "\n",
      "      OHX31CTC       year  \n",
      "0         b'S'  2011-2012  \n",
      "1         b'U'  2011-2012  \n",
      "2         b'S'  2011-2012  \n",
      "3         b'Z'  2011-2012  \n",
      "4         b'S'  2011-2012  \n",
      "...        ...        ...  \n",
      "8361      b'S'  2017-2018  \n",
      "8362      b'Z'  2017-2018  \n",
      "8363      b'S'  2017-2018  \n",
      "8364      b'Z'  2017-2018  \n",
      "8365      b'E'  2017-2018  \n",
      "\n",
      "[35909 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_od)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c02f03",
   "metadata": {},
   "source": [
    "**c. report the number of cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f70e95be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39156, 35909)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], df_od.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ad3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
