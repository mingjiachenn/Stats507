{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962aaaea",
   "metadata": {},
   "source": [
    "## GSI comments\n",
    "\n",
    "Overall: -2 for imports not collected at top.\n",
    "\n",
    "-4 for missing docstring in all functions. \n",
    "\n",
    "-2 if inconsistent spacing around assignment =. \n",
    "\n",
    "Q1: -5 for incorrect output. (uniform would not return integer but float) \n",
    "\n",
    "Q2: -6 for incorrect MC study and no formatted table or description. \n",
    "\n",
    "Q3: -1 for long variable name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12403e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5d332",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-2 for imports not collected at top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5518adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from timeit import Timer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a6291",
   "metadata": {},
   "source": [
    "# Question 0 - Code review warmup [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd64728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = [(1, 3, 5), (0, 1, 2), (1, 9, 8)]\n",
    "op = []\n",
    "for m in range(len(sample_list)):\n",
    "    li = [sample_list[m]]\n",
    "    for n in range(len(sample_list)):\n",
    "        if (sample_list[m][0] == sample_list[n][0] and\n",
    "                sample_list[m][2] != sample_list[n][2]):\n",
    "            li.append(sample_list[n])\n",
    "    op.append(sorted(li, key=lambda dd: dd[2], reverse=True)[0])\n",
    "res = list(set(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b23e0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 2), (1, 9, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4b2656",
   "metadata": {},
   "source": [
    "**a. describe the task that the code accomplishes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba7519",
   "metadata": {},
   "source": [
    "The code selects tuples that the first element is unique from the sample_list.\n",
    "\n",
    "When the first element is equal, compare the 3rd element and choose the one with larger element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0153d09",
   "metadata": {},
   "source": [
    "**b. write a short code review**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8893df5",
   "metadata": {},
   "source": [
    "1. It is important to keep an approperiate indent while coding, since the indent caan affect the logical relationship between different commands.\n",
    "\n",
    "2. The number of tuple index begins from zero, to which we should pay attention when coding.\n",
    "\n",
    "3. To make the snippet more efficient, we can store the index of tuples that has already occured instead of using the `set` fuction to delete duplicate.\n",
    "\n",
    "4. Appropriate comments should be added to make the snippet more readable. \n",
    "\n",
    "5. We can use letter such as `l` to denotes the code `len(sample_list)`, so that the snippet can be more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a5e3a",
   "metadata": {},
   "source": [
    "# Question 1 - List of Tuples [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7cd41",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-4 for missing docstring in all functions.\n",
    "\n",
    "Q1: -5 for incorrect output. (uniform would not return integer but float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b38b7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lis_tup(n, k=5, low=1, high=5):\n",
    "    \"\"\"\n",
    "    Generate a random list of n k-tuples containing integers ranging from low to high.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : integer\n",
    "        The number of tuples in the list.\n",
    "    k: integer, optional\n",
    "        The length of the tuples created. The default is 5.\n",
    "    low : integer, optional\n",
    "        The low end of the range to generate integers from. The default is 1.\n",
    "    high : integer, optional\n",
    "        The high end of hte range to generate integers from. The default is 5.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of length `n` with tuples of size `tup_size` consting of uniform\n",
    "    random integers in [low, high).\n",
    "    \"\"\"\n",
    "    lis = [tuple(np.random.randint(low, high) for i in range(k)) for j in range(n)]\n",
    "    return lis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639495c3",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-2 if inconsistent spacing around assignment =."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "088968ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "k = 5\n",
    "low = 1\n",
    "high = 5\n",
    "\n",
    "ast_lis = lis_tup(n, k, low, high)\n",
    "\n",
    "# assert the type of the result is list\n",
    "assert type(ast_lis) == list\n",
    "\n",
    "# assert the list is composed by tuples\n",
    "for i in range(len(ast_lis)):\n",
    "    assert type(ast_lis[i]) == tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f75a49",
   "metadata": {},
   "source": [
    "# Question 2 - Refactor the Snippet [40 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72141167",
   "metadata": {},
   "source": [
    "**a. encapsulate the code snippet from the warmup into a function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c48f4e",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-4 for missing docstring in all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfe0730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_a(sample_list, first_cmp=0, second_cmp=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Find tuples with maximum value in one position by unique value in another.\n",
    "    \n",
    "    ----------\n",
    "    sample_list : list of tuples\n",
    "        The list of tuples to organize as described above.\n",
    "    first_cmp : int\n",
    "        The position to determine whether the element is unique. The default is 0.\n",
    "    second_cmp : int\n",
    "        The position to compare when the element in the first position is not unique. \n",
    "        The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of all tuples, in which the element on the first position is unique. \n",
    "    When it is not equal, chose the tuple with the largest element on the second position. \n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    op = []\n",
    "    \n",
    "    for m in range(len(sample_list)):\n",
    "        li = [sample_list[m]]\n",
    "        for n in range(len(sample_list)):\n",
    "            if (sample_list[m][first_cmp] == sample_list[n][first_cmp] and\n",
    "                sample_list[m][second_cmp] != sample_list[n][second_cmp]):\n",
    "                li.append(sample_list[n])\n",
    "                \n",
    "        op.append(sorted(li, key=lambda dd: dd[second_cmp], reverse=True)[0])\n",
    "        \n",
    "    res = list(set(op))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b7dce",
   "metadata": {},
   "source": [
    "**b. write an improved version of the function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20744c5d",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-4 for missing docstring in all functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12c81834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_b(sample_list, first_cmp=0, second_cmp=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Find tuples with maximum value in one position by unique value in another.\n",
    "    \n",
    "    ----------\n",
    "    sample_list : list of tuples\n",
    "        The list of tuples to organize as described above.\n",
    "    first_cmp : int\n",
    "        The position to determine whether the element is unique. The default is 0.\n",
    "    second_cmp : int\n",
    "        The position to compare when the element in the first position is not unique.\n",
    "        The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of all tuples, in which the element on the first position is unique. \n",
    "    When it is not equal, chose the tuple with the largest element on the second position. \n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    op = []\n",
    "    appeared_idx = []\n",
    "    l = len(sample_list)\n",
    "    \n",
    "    for m in range(l):\n",
    "        \n",
    "        # filter the tuples that have already appeared\n",
    "        if m in appeared_idx:\n",
    "            continue\n",
    "            \n",
    "        li = [sample_list[m]]\n",
    "        \n",
    "        for n in range(l):\n",
    "            if (sample_list[m][first_cmp] == sample_list[n][first_cmp] and\n",
    "                sample_list[m][second_cmp] != sample_list[n][second_cmp]):\n",
    "\n",
    "                appeared_idx.append(n)\n",
    "                li.append(sample_list[n])\n",
    "                \n",
    "        op.append(sorted(li, key=lambda dd: dd[second_cmp], reverse=True)[0])\n",
    "        \n",
    "    res = op\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19171b4a",
   "metadata": {},
   "source": [
    "**c. Write a function from scratch to accomplish the same task as the previous two parts. Your solution should traverse the input list of tuples no more than twice.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874fd7e",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "**-4 for missing docstring in all functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53e4732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tuple_c(sample_list, first_cmp=0, second_cmp=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Find tuples with maximum value in one position by unique value in another.\n",
    "    \n",
    "    ----------\n",
    "    sample_list : list of tuples\n",
    "        The list of tuples to organize as described above.\n",
    "    first_cmp : int\n",
    "        The position to determine whether the element is unique. The default is 0.\n",
    "    second_cmp : int\n",
    "        The position to compare when the element in the first position is not unique.\n",
    "        The default is 2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of all tuples, in which the element on the first position is unique. \n",
    "    When it is not equal, chose the tuple with the largest element on the second position. \n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure first_com and second_com have corresponding elements in the tuples\n",
    "    assert first_cmp < len(sample_list[0])\n",
    "    assert second_cmp < len(sample_list[0])\n",
    "    \n",
    "    dic_tup = {}\n",
    "    \n",
    "    for tup in sample_list:\n",
    "        dic_add = {}\n",
    "        tup_add = True\n",
    "        \n",
    "        for key, value in dic_tup.items():\n",
    "            if key[first_cmp] == tup[first_cmp] and key[second_cmp] != tup[second_cmp]:\n",
    "                dic_tup[key].append(tup)\n",
    "                tup_add = False\n",
    "        \n",
    "        if tup_add:\n",
    "            dic_add[tup] = [tup]\n",
    "        \n",
    "        dic_tup = {**dic_add, **dic_tup}        \n",
    "                \n",
    "    res = set()\n",
    "    for value in dic_tup.values():\n",
    "        tup = sorted(value, key=lambda dd: dd[second_cmp], reverse=True)[0] \n",
    "        res.add(tup)\n",
    "        \n",
    "    res = list(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf68d2",
   "metadata": {},
   "source": [
    "**d. Use the function you wrote in question 1 to generate a list of tuples as input(s), run and summarize a small Monte Carlo study comparing the execution times of the three functions above (a-c).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35639bb3",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "-2 if inconsistent spacing around assignment =.\n",
    "\n",
    "Q2: -6 for incorrect MC study and no formatted table or description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5711e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Function  mean time\n",
      "0  filter_tuple_a   0.094076\n",
      "1  filter_tuple_b   0.061759\n",
      "2  filter_tuple_c   0.030752\n"
     ]
    }
   ],
   "source": [
    "sample_list = lis_tup(n=1000, k=5, low=0, high=1000)\n",
    "\n",
    "time = defaultdict(list)\n",
    "\n",
    "for f in [filter_tuple_a, filter_tuple_b, filter_tuple_c]:\n",
    "    t = Timer('f(n)', globals={'f': f, 'n': sample_list})\n",
    "    tm = t.repeat(repeat=100, number=1)\n",
    "    time[\"Function\"].append(f.__name__)\n",
    "    time[\"mean time\"].append(np.mean(tm))\n",
    "    \n",
    "tab1 = pd.DataFrame(time)\n",
    "\n",
    "print(tab1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd88331",
   "metadata": {},
   "source": [
    "The execution times of the `filter_tuple_a`, `filter_tuple_b` and `filter_tuple_c` functions decrease one by one.\n",
    "To be more specific, the execution time of `filter_tuple_c` is only $\\frac{1}{3}$ of that of `filter_tuple_a`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85beb6f5",
   "metadata": {},
   "source": [
    "# Question 3 - [30 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104999fa",
   "metadata": {},
   "source": [
    "**a. read and append the demographic datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75524cfc",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "Q3: -1 for long variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3262e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT'\n",
    "url2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT'\n",
    "url3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT'\n",
    "url4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT'\n",
    "\n",
    "df11_12 = pd.read_sas(url1)\n",
    "df11_12 = df11_12[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \n",
    "                   'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df11_12['year'] = ['2011-2012' for i in range(len(df11_12))]\n",
    "\n",
    "df13_14 = pd.read_sas(url2)\n",
    "df13_14 = df13_14[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \n",
    "                   'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df13_14['year'] = ['2013-2014' for i in range(len(df13_14))]\n",
    "\n",
    "df15_16 = pd.read_sas(url3)\n",
    "df15_16 = df15_16[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \n",
    "                   'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df15_16['year'] = ['2015-2016' for i in range(len(df15_16))]\n",
    "\n",
    "df17_18 = pd.read_sas(url4)\n",
    "df17_18 = df17_18[['SEQN', 'RIDAGEYR', 'RIDRETH3', 'DMDEDUC2', 'DMDMARTL', \n",
    "                   'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']]\n",
    "df17_18['year'] = ['2017-2018' for i in range(len(df17_18))]\n",
    "\n",
    "df = pd.concat([df11_12, df13_14, df15_16, df17_18], axis=0)\n",
    "\n",
    "df['SEQN'] = df['SEQN'].astype('int')\n",
    "df['RIDAGEYR'] = df['RIDAGEYR'].astype('int')\n",
    "df['RIDRETH3'] = df['RIDRETH3'].astype('int')\n",
    "df['RIDSTATR'] = df['RIDSTATR'].astype('int')\n",
    "\n",
    "df = df.rename(columns = {'SEQN': 'sequence number',\n",
    "                         'RIDAGEYR': 'Age', \n",
    "                         'RIDRETH3': 'Race',\n",
    "                         'DMDEDUC2': 'Education level',\n",
    "                         'DMDMARTL': 'Marital status',\n",
    "                         'RIDSTATR': 'examination status',\n",
    "                         'SDMVPSU': 'pseudo-PSU variable',\n",
    "                         'SDMVSTRA': 'pseudo-stratum variable',\n",
    "                         'WTMEC2YR': 'Interviewed and MEC examined participants.',\n",
    "                         'WTINT2YR': 'Interviewed participants.'})\n",
    "\n",
    "\n",
    "f = open('NHANS.pkl', 'wb')\n",
    "\n",
    "pickle.dump(df, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2895569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sequence number  Age  Race  Education level  Marital status  \\\n",
      "0               62161   22     3              3.0             5.0   \n",
      "1               62162    3     1              NaN             NaN   \n",
      "2               62163   14     6              NaN             NaN   \n",
      "3               62164   44     3              4.0             1.0   \n",
      "4               62165   14     4              NaN             NaN   \n",
      "...               ...  ...   ...              ...             ...   \n",
      "9249           102952   70     6              3.0             1.0   \n",
      "9250           102953   42     1              3.0             4.0   \n",
      "9251           102954   41     4              5.0             5.0   \n",
      "9252           102955   14     4              NaN             NaN   \n",
      "9253           102956   38     3              4.0             3.0   \n",
      "\n",
      "      examination status  pseudo-PSU variable  pseudo-stratum variable  \\\n",
      "0                      2                  1.0                     91.0   \n",
      "1                      2                  3.0                     92.0   \n",
      "2                      2                  3.0                     90.0   \n",
      "3                      2                  1.0                     94.0   \n",
      "4                      2                  2.0                     90.0   \n",
      "...                  ...                  ...                      ...   \n",
      "9249                   2                  2.0                    138.0   \n",
      "9250                   2                  2.0                    137.0   \n",
      "9251                   2                  1.0                    144.0   \n",
      "9252                   2                  1.0                    136.0   \n",
      "9253                   2                  1.0                    142.0   \n",
      "\n",
      "      Interviewed and MEC examined participants.  Interviewed participants.  \\\n",
      "0                                  104236.582554              102641.406474   \n",
      "1                                   16116.354010               15457.736897   \n",
      "2                                    7869.485117                7397.684828   \n",
      "3                                  127965.226204              127351.373299   \n",
      "4                                   13384.042162               12209.744980   \n",
      "...                                          ...                        ...   \n",
      "9249                                18338.711104               16896.276203   \n",
      "9250                                63661.951573               61630.380013   \n",
      "9251                                17694.783346               17160.895269   \n",
      "9252                                14871.839636               14238.445922   \n",
      "9253                                39426.299948               38645.740291   \n",
      "\n",
      "           year  \n",
      "0     2011-2012  \n",
      "1     2011-2012  \n",
      "2     2011-2012  \n",
      "3     2011-2012  \n",
      "4     2011-2012  \n",
      "...         ...  \n",
      "9249  2017-2018  \n",
      "9250  2017-2018  \n",
      "9251  2017-2018  \n",
      "9252  2017-2018  \n",
      "9253  2017-2018  \n",
      "\n",
      "[39156 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d60eea",
   "metadata": {},
   "source": [
    "**b. read and append the oral health and dentition dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5284fa",
   "metadata": {},
   "source": [
    "**Corrections for PS6 Q3**\n",
    "\n",
    "Q3: -1 for long variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90a447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingjia/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sas/sas_xport.py:475: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[x] = v\n"
     ]
    }
   ],
   "source": [
    "url5 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT'\n",
    "url6 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT'\n",
    "url7 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT'\n",
    "url8 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT'\n",
    "\n",
    "required_columns = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "df17_18_od = pd.read_sas(url8)\n",
    "for col in df17_18_od.columns:\n",
    "    if col.startswith('OHX'):\n",
    "        if (col.lstrip('OHX').rstrip('TC')).isdigit():\n",
    "            required_columns.append(col)\n",
    "        elif (col.lstrip('OHX').rstrip('CTC')).isdigit():\n",
    "            required_columns.append(col)\n",
    "df17_18_od = df17_18_od[required_columns]\n",
    "df17_18_od['year'] = ['2017-2018' for i in range(len(df17_18_od))]\n",
    "\n",
    "df11_12_od = pd.read_sas(url5)\n",
    "df11_12_od = df11_12_od[required_columns]\n",
    "df11_12_od['year'] = ['2011-2012' for i in range(len(df11_12_od))]\n",
    "\n",
    "\n",
    "df13_14_od = pd.read_sas(url6)\n",
    "df13_14_od = df13_14_od[required_columns]\n",
    "df13_14_od['year'] = ['2013-2014' for i in range(len(df13_14_od))]\n",
    "\n",
    "\n",
    "df15_16_od = pd.read_sas(url7)\n",
    "df15_16_od = df15_16_od[required_columns]\n",
    "df15_16_od['year'] = ['2015-2016' for i in range(len(df15_16_od))]\n",
    "\n",
    "df_od = pd.concat([df11_12_od, df13_14_od, df15_16_od, df17_18_od], axis=0, sort=False)\n",
    "\n",
    "df_od['SEQN'] = df_od['SEQN'].astype('int')\n",
    "df_od['OHDDESTS'] = df_od['OHDDESTS'].astype('int')\n",
    "\n",
    "df_od = df_od.rename(columns = {'SEQN': 'Sequence number',\n",
    "                                'OHDDESTS': 'Dentition Status'})\n",
    "\n",
    "f = open('OHXDEN.pkl', 'wb')\n",
    "\n",
    "pickle.dump(df_od, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a578c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sequence number  Dentition Status  OHX01TC  OHX02TC  OHX03TC  OHX04TC  \\\n",
      "0               62161                 1      4.0      2.0      2.0      2.0   \n",
      "1               62162                 1      4.0      4.0      4.0      1.0   \n",
      "2               62163                 1      4.0      2.0      2.0      2.0   \n",
      "3               62164                 1      4.0      2.0      2.0      2.0   \n",
      "4               62165                 1      4.0      2.0      2.0      2.0   \n",
      "...               ...               ...      ...      ...      ...      ...   \n",
      "8361           102952                 1      2.0      2.0      2.0      2.0   \n",
      "8362           102953                 1      2.0      2.0      2.0      2.0   \n",
      "8363           102954                 1      2.0      2.0      2.0      2.0   \n",
      "8364           102955                 1      4.0      2.0      2.0      2.0   \n",
      "8365           102956                 1      4.0      4.0      2.0      2.0   \n",
      "\n",
      "      OHX05TC  OHX06TC  OHX07TC  OHX08TC  ...  OHX23CTC  OHX24CTC  OHX25CTC  \\\n",
      "0         2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "1         1.0      1.0      1.0      1.0  ...      b'D'      b'D'      b'D'   \n",
      "2         2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "3         2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "4         2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "...       ...      ...      ...      ...  ...       ...       ...       ...   \n",
      "8361      2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "8362      2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "8363      2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "8364      2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "8365      2.0      2.0      2.0      2.0  ...      b'S'      b'S'      b'S'   \n",
      "\n",
      "      OHX26CTC  OHX27CTC  OHX28CTC  OHX29CTC  OHX30CTC  OHX31CTC       year  \n",
      "0         b'S'      b'S'      b'S'      b'S'      b'Z'      b'S'  2011-2012  \n",
      "1         b'D'      b'D'      b'D'      b'D'      b'U'      b'U'  2011-2012  \n",
      "2         b'S'      b'S'      b'S'      b'S'      b'Y'      b'S'  2011-2012  \n",
      "3         b'S'      b'S'      b'S'      b'S'      b'Z'      b'Z'  2011-2012  \n",
      "4         b'S'      b'S'      b'S'      b'S'      b'S'      b'S'  2011-2012  \n",
      "...        ...       ...       ...       ...       ...       ...        ...  \n",
      "8361      b'S'      b'S'      b'S'      b'S'      b'S'      b'S'  2017-2018  \n",
      "8362      b'S'      b'S'      b'S'      b'S'      b'S'      b'Z'  2017-2018  \n",
      "8363      b'S'      b'S'      b'S'      b'F'      b'S'      b'S'  2017-2018  \n",
      "8364      b'S'      b'S'      b'S'      b'S'      b'S'      b'Z'  2017-2018  \n",
      "8365      b'S'      b'S'      b'S'      b'S'      b'S'      b'E'  2017-2018  \n",
      "\n",
      "[35909 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_od)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c02f03",
   "metadata": {},
   "source": [
    "**c. report the number of cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f70e95be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39156, 35909)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0], df_od.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ad3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
